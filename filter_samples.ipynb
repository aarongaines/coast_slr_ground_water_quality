{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Set Starting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, slr_pkg.clean_load_data as cld, slr_pkg.para as para\n",
    "from slr_pkg.clean_load_data import open_table\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Get current working directory\n",
    "bp = Path(os.getcwd())\n",
    "\n",
    "# Set sample data directory.\n",
    "edf_path = bp / 'geotracker_edf_results'\n",
    "gama_path = bp / 'gama_results'\n",
    "\n",
    "# Set location data directory.\n",
    "geo_xy_path = bp / 'geotracker_xy'\n",
    "gama_xy_path = bp / \"gama_xy\"\n",
    "\n",
    "# Set results directory\n",
    "results_path = bp / \"results\"\n",
    "\n",
    "# Ask for county to gather data for.\n",
    "# area = input('Enter county: ')\n",
    "area = 'SanDiego'\n",
    "\n",
    "# List of contaminants.\n",
    "chems = para.conts11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and Concat Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Geotracker file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\geotracker_edf_results\\SanDiegoEDF.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_ddw_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_dpr_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_dwr_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_gama_dom_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_gama_sp-study_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_gama_usgs_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_usgs_nwis_sandiego_v2.zip\n",
      "Loading GAMA file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_results\\gama_wb_cleanup_sandiego_v2.zip\n",
      "Concatenating GAMA and Geotracker dataframes. \n",
      "\n",
      "Checking for missing values. \n",
      "\n",
      "Creating group ID (GID). \n",
      "\n",
      "Creating SID. \n",
      "\n",
      "            LOGDATE     PARLABEL        PARVAL PARVQ       REPDL       UNITS  \\\n",
      "0        2007-05-23   TPHSTDSOLV  1000000000.0     =       500.0        UG/L   \n",
      "1        2004-07-01          GRO   953000000.0     =  25000000.0        UG/L   \n",
      "2        2013-11-25          GRO   761000000.0     =  25000000.0        UG/L   \n",
      "3        2013-11-25          GRO   761000000.0     =  25000000.0        UG/L   \n",
      "4        2002-05-01  GROLROC4C12   640000000.0     =   4000000.0        UG/L   \n",
      "...             ...          ...           ...   ...         ...         ...   \n",
      "7546073  2011-05-26        REDOX        -370.0     =      -800.0  MILLIVOLTS   \n",
      "7546074  2011-05-25        REDOX        -370.0     =      -800.0  MILLIVOLTS   \n",
      "7546075  2011-05-26        REDOX        -380.0     =      -800.0  MILLIVOLTS   \n",
      "7546076  2010-06-16        REDOX        -390.0     =      -800.0  MILLIVOLTS   \n",
      "7546077  2014-12-09        REDOX        -400.0     =      -800.0  MILLIVOLTS   \n",
      "\n",
      "                           WID                                  GID  \\\n",
      "0              T0607302969-SB8        (T0607302969-SB8, 2007-05-23)   \n",
      "1               T0607390928-B1         (T0607390928-B1, 2004-07-01)   \n",
      "2              T0607390928-DW3        (T0607390928-DW3, 2013-11-25)   \n",
      "3              T0607390928-MW1        (T0607390928-MW1, 2013-11-25)   \n",
      "4            T0607300825-MW-10      (T0607300825-MW-10, 2002-05-01)   \n",
      "...                        ...                                  ...   \n",
      "7546073  T10000001489-NCW-002A  (T10000001489-NCW-002A, 2011-05-26)   \n",
      "7546074  T10000001489-NCW-005C  (T10000001489-NCW-005C, 2011-05-25)   \n",
      "7546075  T10000001489-NCW-003C  (T10000001489-NCW-003C, 2011-05-26)   \n",
      "7546076  T10000001489-NCW-003C  (T10000001489-NCW-003C, 2010-06-16)   \n",
      "7546077  T10000001489-NCW-002A  (T10000001489-NCW-002A, 2014-12-09)   \n",
      "\n",
      "                                                    SID  \n",
      "0           ((T0607302969-SB8, 2007-05-23), TPHSTDSOLV)  \n",
      "1                   ((T0607390928-B1, 2004-07-01), GRO)  \n",
      "2                  ((T0607390928-DW3, 2013-11-25), GRO)  \n",
      "3                  ((T0607390928-MW1, 2013-11-25), GRO)  \n",
      "4        ((T0607300825-MW-10, 2002-05-01), GROLROC4C12)  \n",
      "...                                                 ...  \n",
      "7546073    ((T10000001489-NCW-002A, 2011-05-26), REDOX)  \n",
      "7546074    ((T10000001489-NCW-005C, 2011-05-25), REDOX)  \n",
      "7546075    ((T10000001489-NCW-003C, 2011-05-26), REDOX)  \n",
      "7546076    ((T10000001489-NCW-003C, 2010-06-16), REDOX)  \n",
      "7546077    ((T10000001489-NCW-002A, 2014-12-09), REDOX)  \n",
      "\n",
      "[7546078 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "edf_files = edf_path.glob('**/*{}*.zip'.format(area))\n",
    "gama_files = gama_path.glob('**/*{}*.zip'.format(area.lower()))\n",
    "\n",
    "samples = cld.Sample_Data.full_dataset(edf_files, gama_files)\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7546078\n",
      "7546078\n"
     ]
    }
   ],
   "source": [
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Geotracker file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\geotracker_xy\\SanDiegoGeoXY.zip\n",
      "Loading Geotracker file. e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\gama_xy\\gama_location_construction_v2.zip\n",
      "Concatenating GAMA and Geotracker dataframes. \n",
      "\n",
      "Checking for missing values. \n",
      "\n",
      "                 FIELD_PT_CLASS   LATITUDE   LONGITUDE                  WID\n",
      "0                            MW  33.121798 -117.319569    T0607300319-VEW-1\n",
      "1                            MW  33.121793 -117.319447    T0607300319-VEW-2\n",
      "2                            MW  33.183242 -117.369407    T0607301407-OMW-1\n",
      "3                            MW  33.183227 -117.369231    T0607301407-OMW-2\n",
      "4                            MW  33.183421 -117.369302    T0607301407-OMW-4\n",
      "...                         ...        ...         ...                  ...\n",
      "298597               MONITORING  38.372833 -122.912156     T0609700197-MW-2\n",
      "298598               MONITORING   38.44332 -122.674776      T0609700537-MW9\n",
      "298599               MONITORING  38.426035 -122.755992     T0609700756-MW-2\n",
      "298600  IRRIGATION / INDUSTRIAL  38.250109 -122.692601  T0609701035-DW-4330\n",
      "298601               MONITORING  38.290317 -122.458544     T0609704633-MW-3\n",
      "\n",
      "[298602 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "geo_xy_files = geo_xy_path.glob('**/*{}*.zip'.format(area))\n",
    "gama_xy_files = gama_xy_path.glob('**/*.zip')\n",
    "\n",
    "locations = cld.Location_Data.full_dataset(geo_xy_files, gama_xy_files)\n",
    "\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Sample and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7546078\n",
      "7546078\n"
     ]
    }
   ],
   "source": [
    "# Join well location data to sample results.\n",
    "samples = samples.merge(locations, left_on='WID', right_on='WID', how='inner')\n",
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join MCL Table to Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MCL table \n",
      "\n",
      "Joining MCL values to samples \n",
      "\n",
      "3200356\n",
      "3200356\n"
     ]
    }
   ],
   "source": [
    "print('Loading MCL table \\n')\n",
    "\n",
    "# Create path to mcl table.\n",
    "mcl_path = bp / 'MCLs.xlsx'\n",
    "\n",
    "# Open mcl table.\n",
    "mcl = pd.read_excel(mcl_path,sheet_name='MCL', engine='openpyxl')\n",
    "\n",
    "# join MCL values to sample results\n",
    "print('Joining MCL values to samples \\n')\n",
    "samples = samples.merge(mcl, left_on='PARLABEL', right_on='chem_abrv', how='inner')\n",
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Unit Conversion Data to Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188665\n",
      "3188665\n"
     ]
    }
   ],
   "source": [
    "# Load conversion tables.\n",
    "metric_conversion = pd.read_excel(bp / 'unit_conversion.xlsx', sheet_name='metric')\n",
    "\n",
    "# join coversion factors to samples based on sample unit.\n",
    "samples = samples.merge(metric_conversion, how='inner', left_on='UNITS', right_on='start_unit')\n",
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188665\n",
      "3188665\n"
     ]
    }
   ],
   "source": [
    "# Create mask for samples with MCL units in UG/L and converts sample result units to UG/L.\n",
    "mask = samples['UNITS'] != samples['units']\n",
    "\n",
    "# Multiply sample results by conversion factor.\n",
    "samples.loc[mask, 'PARVAL'] = samples['PARVAL'] * samples['coef']\n",
    "samples['UNITS'] = 'UG/L'\n",
    "\n",
    "# Drop columns that are not needed.\n",
    "samples.drop(columns=['REPDL','chem_abrv', 'units','comp_conc_type','start_unit', 'coef'], inplace=True)\n",
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Exceedence and Magnitude Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exceedence attribute, true if sample result exceeds reporting limit.\n",
    "samples['exceedence'] = samples['PARVAL'] > samples['comp_conc_val']\n",
    "\n",
    "# Create magnitude attribute. Sample result value divided by the comparison concentration value (MCL or Action level) minus 1.\n",
    "samples['magnitude'] = (samples['PARVAL'] / samples['comp_conc_val']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188665\n",
      "3188665\n"
     ]
    }
   ],
   "source": [
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **All Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples.to_csv(results_path / '{}_all_sample_results.csv'.format(area.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Specific Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188665\n",
      "3188665\n"
     ]
    }
   ],
   "source": [
    "# subset of specific samples meeting parameters.\n",
    "spec_samples = samples\n",
    "print(len(spec_samples))\n",
    "print(len(spec_samples['SID'].unique()))\n",
    "# Select spec_samples taken since 2010.\n",
    "spec_samples = spec_samples.loc[spec_samples['LOGDATE'] >= '2012-01-01']\n",
    "\n",
    "# Select samples with contaminants of interest.\n",
    "spec_samples = spec_samples.loc[spec_samples['PARLABEL'].isin(chems)]\n",
    "\n",
    "# Create groups of spec_samples based on WID and PARLABEL(contaminant label).\n",
    "sample_groups = spec_samples.groupby(['WID'])['PARLABEL'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503035\n",
      "503035\n"
     ]
    }
   ],
   "source": [
    "print(len(spec_samples))\n",
    "print(len(spec_samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([18, 18, 18, 18, 18, 18, 18, 18, 18, 13, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 3, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 6, 3, 3, 5, 6, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 5, 3, 3, 5, 6, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 3, 13, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 2, 3, 13, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1])\n",
      "dict_values([4, 4, 4, 4, 4, 1, 4, 4, 2, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 3, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 4, 3, 6, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 4, 3, 6, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 3, 3, 6, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 5, 2, 2, 3, 5, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 5, 3, 3, 5, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 1, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 2, 2, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 2, 2, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 4, 3, 6, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 4, 3, 6, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 4, 3, 6, 1])\n",
      "dict_values([2, 3, 3, 3, 3, 3, 3, 5, 4, 7, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 4, 3, 6, 1])\n",
      "dict_values([4, 4, 4, 4, 4, 1, 4, 4, 2, 3, 3])\n",
      "dict_values([1, 2, 2, 2, 2, 2, 2, 2, 3, 5, 1])\n",
      "dict_values([1, 2, 2, 2, 2, 3, 2, 2, 2, 5, 1])\n",
      "dict_values([3, 4, 4, 4, 4, 3, 4, 4, 4, 6, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 3])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 4, 1, 1, 4, 6, 1])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 1])\n",
      "dict_values([40, 40, 40, 40, 40, 3, 40, 40, 3, 7, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 6, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 2])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 5, 4])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 7, 2])\n",
      "dict_values([6, 6, 6, 6, 6, 2, 6, 6, 2, 8, 5])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 6, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 5, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 3, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1])\n",
      "dict_values([4, 4, 4, 4, 4, 2, 4, 4, 2, 7, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([5, 5, 5, 5, 5, 3, 5, 5, 3, 6, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 5, 1])\n",
      "dict_values([1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 1])\n",
      "dict_values([6, 6, 6, 6, 6, 2, 6, 6, 2, 5, 4])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 1])\n",
      "dict_values([2, 3, 3, 3, 3, 2, 3, 3, 3, 5, 1])\n",
      "dict_values([2, 3, 3, 3, 3, 4, 3, 3, 5, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 1])\n",
      "dict_values([5, 5, 5, 5, 5, 4, 5, 5, 4, 6, 5])\n",
      "dict_values([8, 8, 8, 8, 8, 6, 8, 8, 2, 7, 1])\n",
      "dict_values([5, 5, 5, 5, 5, 1, 5, 5, 1, 4, 4])\n",
      "dict_values([6, 6, 6, 6, 6, 2, 6, 6, 2, 4, 5])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 5, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 6, 2])\n",
      "dict_values([5, 5, 5, 5, 5, 3, 5, 5, 3, 6, 3])\n",
      "dict_values([5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 3])\n",
      "dict_values([4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 3, 3, 1, 2, 3])\n",
      "dict_values([5, 5, 5, 5, 5, 5, 5, 4, 5, 11, 5])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([5, 5, 5, 5, 5, 5, 5, 4, 5, 11, 5])\n",
      "dict_values([5, 5, 5, 5, 5, 5, 5, 4, 5, 11, 5])\n",
      "dict_values([32, 32, 31, 32, 32, 2, 32, 33, 4, 111, 5])\n",
      "dict_values([33, 33, 33, 33, 33, 2, 33, 34, 4, 98, 4])\n",
      "dict_values([25, 25, 25, 25, 25, 3, 25, 26, 3, 82, 5])\n",
      "dict_values([31, 31, 31, 31, 31, 2, 31, 32, 4, 21, 5])\n",
      "dict_values([25, 25, 25, 25, 25, 2, 25, 25, 4, 19, 4])\n",
      "dict_values([29, 29, 29, 29, 29, 2, 29, 30, 3, 95, 5])\n",
      "dict_values([28, 28, 28, 28, 28, 3, 28, 29, 5, 74, 8])\n",
      "dict_values([35, 35, 35, 35, 35, 2, 35, 35, 4, 97, 7])\n",
      "dict_values([83, 85, 85, 85, 85, 5, 85, 85, 5, 10, 65])\n",
      "dict_values([16, 18, 18, 18, 18, 2, 18, 18, 2, 4, 3])\n",
      "dict_values([5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 8])\n",
      "dict_values([3, 3, 3, 3, 3, 21, 3, 3, 21, 7, 8])\n",
      "dict_values([3, 3, 3, 3, 3, 21, 3, 8, 21, 7, 8])\n",
      "dict_values([2, 2, 2, 2, 2, 20, 2, 2, 20, 6, 4])\n",
      "dict_values([3, 3, 3, 3, 3, 20, 3, 3, 20, 6, 4])\n",
      "dict_values([3, 3, 3, 3, 3, 19, 3, 3, 19, 6, 4])\n",
      "dict_values([3, 3, 3, 3, 3, 20, 3, 3, 20, 6, 4])\n",
      "dict_values([3, 3, 3, 3, 3, 20, 3, 3, 20, 6, 4])\n",
      "dict_values([3, 3, 3, 3, 3, 21, 3, 8, 21, 7, 7])\n",
      "dict_values([3, 3, 3, 3, 3, 20, 3, 3, 20, 7, 8])\n",
      "dict_values([7, 7, 7, 7, 7, 14, 7, 7, 14, 9, 5])\n",
      "dict_values([7, 7, 7, 7, 7, 13, 7, 7, 13, 8, 5])\n",
      "dict_values([8, 8, 8, 8, 8, 14, 8, 8, 14, 9, 5])\n",
      "dict_values([8, 8, 8, 8, 8, 14, 8, 8, 14, 8, 5])\n",
      "dict_values([8, 8, 8, 8, 8, 14, 8, 8, 14, 9, 5])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4])\n",
      "dict_values([4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 4, 3, 3, 4, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 4, 3, 3, 4, 5, 2])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 5, 2])\n",
      "dict_values([3, 3, 3, 3, 3, 6, 3, 3, 3, 7, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 5, 2, 2, 3, 7, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 5, 3, 3, 3, 7, 2])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 7, 2])\n",
      "dict_values([4, 4, 4, 4, 4, 3, 4, 4, 3, 6, 2])\n",
      "dict_values([7, 7, 7, 7, 7, 1, 7, 7, 3, 5, 7])\n",
      "dict_values([7, 7, 7, 7, 7, 2, 7, 7, 2, 5, 5])\n",
      "dict_values([6, 6, 6, 6, 6, 2, 6, 6, 2, 5, 5])\n",
      "dict_values([8, 8, 8, 8, 8, 3, 8, 8, 3, 4, 6])\n",
      "dict_values([6, 7, 7, 6, 7, 2, 7, 6, 3, 4, 6])\n",
      "dict_values([3, 3, 5, 3, 3, 2, 3, 3, 2, 4, 1])\n",
      "dict_values([9, 9, 9, 9, 9, 8, 9, 9, 8, 3, 4])\n",
      "dict_values([10, 10, 10, 10, 10, 9, 10, 10, 9, 3, 5])\n",
      "dict_values([10, 10, 10, 10, 10, 9, 10, 10, 10, 8, 6])\n",
      "dict_values([4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 5])\n",
      "dict_values([10, 10, 10, 10, 10, 9, 10, 10, 10, 8, 8])\n",
      "dict_values([10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 7])\n",
      "dict_values([5, 5, 5, 5, 5, 3, 5, 5, 3, 2, 4])\n",
      "dict_values([6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 3])\n",
      "dict_values([9, 9, 9, 9, 9, 9, 9, 9, 9, 12, 5])\n",
      "dict_values([4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 3])\n",
      "dict_values([9, 9, 9, 9, 9, 9, 9, 9, 9, 13, 6])\n",
      "dict_values([9, 9, 9, 9, 9, 9, 9, 9, 9, 14, 6])\n",
      "dict_values([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2])\n",
      "dict_values([7, 7, 7, 7, 7, 7, 7, 7, 7, 10, 1])\n",
      "dict_values([8, 8, 8, 8, 8, 8, 8, 8, 8, 13, 7])\n",
      "dict_values([6, 6, 6, 6, 6, 3, 6, 6, 3, 5, 1])\n",
      "dict_values([10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 6])\n",
      "dict_values([10, 10, 10, 10, 10, 10, 10, 10, 10, 13, 6])\n",
      "dict_values([7, 7, 7, 7, 7, 7, 7, 7, 7, 10, 2])\n",
      "dict_values([11, 11, 11, 11, 11, 9, 11, 11, 9, 13, 10])\n",
      "dict_values([11, 11, 11, 11, 11, 9, 11, 11, 9, 13, 10])\n",
      "dict_values([15, 15, 15, 15, 15, 10, 15, 15, 10, 13, 17])\n",
      "dict_values([4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4])\n",
      "dict_values([9, 9, 9, 9, 9, 7, 9, 9, 7, 10, 10])\n",
      "dict_values([5, 5, 5, 5, 5, 2, 5, 5, 2, 4, 5])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 3, 4, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 5, 2, 4, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 4, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 3, 2, 5, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 14, 6])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 4, 3])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 3, 1, 1, 3, 5, 3])\n",
      "dict_values([2, 2, 2, 2, 2, 4, 2, 2, 4, 6, 4])\n",
      "dict_values([1, 2, 2, 2, 2, 3, 2, 2, 3, 5, 3])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 20, 1, 20, 20])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([18, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([8, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([19, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([19, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([19, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([19, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])\n",
      "dict_values([10, 11, 11, 11, 11, 11, 11, 11, 11, 1, 1])\n",
      "dict_values([2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "dict_values([3, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 19, 19, 19, 19, 7, 19, 19, 7, 19, 19])\n",
      "dict_values([2, 18, 18, 18, 18, 7, 18, 18, 7, 18, 18])\n",
      "dict_values([2, 19, 19, 19, 19, 7, 19, 19, 7, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 7, 19, 19, 7, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 8, 19, 19, 8, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 8, 19, 19, 8, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 9, 19, 19, 9, 19, 19])\n",
      "dict_values([2, 19, 19, 19, 19, 9, 19, 19, 9, 19, 19])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2])\n",
      "dict_values([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([2, 17, 17, 17, 17, 6, 17, 17, 6, 17, 17])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([18, 20, 20, 20, 20, 2, 20, 19, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([18, 19, 19, 19, 19, 2, 19, 19, 2, 19, 19])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([15, 15, 15, 15, 15, 1, 15, 15, 1, 15, 15])\n",
      "dict_values([16, 16, 16, 16, 16, 2, 16, 16, 2, 16, 16])\n",
      "dict_values([12, 13, 13, 13, 13, 2, 13, 13, 1, 13, 13])\n",
      "dict_values([7, 8, 8, 8, 8, 1, 8, 8, 1, 8, 8])\n",
      "dict_values([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
      "dict_values([16, 17, 17, 17, 17, 2, 17, 17, 2, 17, 17])\n",
      "dict_values([20, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([20, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([20, 21, 21, 21, 21, 1, 21, 21, 1, 21, 21])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([16, 17, 17, 17, 17, 2, 17, 17, 2, 17, 17])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([19, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([5, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6])\n",
      "dict_values([5, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5])\n",
      "dict_values([6, 7, 7, 7, 7, 1, 7, 7, 1, 7, 7])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([17, 18, 18, 18, 18, 10, 18, 18, 1, 18, 18])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([10, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([10, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 18, 1, 18, 18])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 19, 1, 19, 19])\n",
      "dict_values([10, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([10, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 1, 18, 17, 1, 18, 18])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
      "dict_values([1, 28, 28, 28, 28, 28, 28, 13, 13, 28, 28])\n",
      "dict_values([16, 17, 17, 17, 17, 2, 17, 17, 1, 17, 17])\n",
      "dict_values([16, 17, 17, 17, 17, 2, 17, 17, 2, 17, 17])\n",
      "dict_values([16, 17, 17, 17, 17, 2, 17, 17, 2, 17, 17])\n",
      "dict_values([20, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([20, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([20, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([4, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5])\n",
      "dict_values([19, 20, 20, 20, 20, 1, 20, 19, 1, 20, 20])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 18, 1, 19, 19])\n",
      "dict_values([18, 19, 19, 19, 19, 1, 19, 18, 1, 19, 19])\n",
      "dict_values([2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
      "dict_values([17, 18, 18, 18, 18, 6, 18, 18, 6, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 6, 18, 18, 6, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 6, 18, 18, 6, 18, 18])\n",
      "dict_values([17, 18, 18, 18, 18, 5, 18, 18, 5, 18, 18])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([18, 19, 19, 19, 19, 6, 19, 19, 6, 19, 19])\n",
      "dict_values([17, 18, 18, 18, 18, 6, 18, 18, 6, 18, 18])\n",
      "dict_values([9, 10, 10, 10, 10, 10, 10, 10, 10, 5, 5])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([17, 18, 18, 18, 18, 6, 18, 18, 6, 18, 18])\n",
      "dict_values([6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
      "dict_values([13, 20, 20, 20, 20, 20, 20, 20, 20, 2, 2])\n",
      "dict_values([5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([14, 21, 21, 21, 21, 2, 21, 21, 2, 21, 21])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([11, 16, 16, 16, 16, 16, 16, 1, 16, 16, 1])\n",
      "dict_values([2, 4, 4, 4, 4, 1, 4, 4, 1, 4, 4])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([9, 11, 11, 11, 11, 11, 11, 11, 11, 1, 1])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([13, 20, 20, 20, 20, 2, 20, 20, 2, 20, 20])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1])\n",
      "dict_values([1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([4, 9, 14, 14, 9, 6, 14, 14, 1, 5, 9])\n",
      "dict_values([19, 49, 49, 49, 49, 33, 49, 49, 5, 48, 48])\n",
      "dict_values([1, 16, 16, 16, 16, 1, 16, 16, 1, 16, 16])\n",
      "dict_values([1, 16, 16, 16, 16, 1, 16, 16, 1, 16, 16])\n",
      "dict_values([6, 17, 17, 17, 17, 8, 17, 17, 1, 17, 17])\n",
      "dict_values([1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
      "dict_values([6, 18, 18, 18, 18, 8, 18, 18, 1, 18, 18])\n",
      "dict_values([1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
      "dict_values([1, 7, 7, 7, 7, 1, 7, 7, 1, 7, 7])\n",
      "dict_values([1, 7, 7, 7, 7, 1, 7, 7, 1, 7, 7])\n",
      "dict_values([1, 34, 34, 34, 34, 1, 34, 34, 1, 34, 34])\n",
      "dict_values([1, 34, 34, 34, 34, 2, 34, 34, 2, 34, 34])\n",
      "dict_values([4, 18, 18, 18, 18, 9, 18, 18, 1, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 9, 18, 18, 1, 18, 18])\n",
      "dict_values([1, 34, 34, 34, 34, 1, 34, 34, 1, 34, 34])\n",
      "dict_values([1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
      "dict_values([1, 33, 33, 33, 33, 1, 33, 33, 1, 33, 33])\n",
      "dict_values([1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3])\n",
      "dict_values([1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3])\n",
      "dict_values([1, 34, 34, 34, 34, 1, 34, 34, 1, 34, 34])\n",
      "dict_values([1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3])\n",
      "dict_values([6, 13, 13, 13, 13, 11, 13, 13, 3, 13, 13])\n",
      "dict_values([6, 14, 14, 14, 14, 11, 14, 14, 3, 14, 14])\n",
      "dict_values([1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1])\n",
      "dict_values([2, 7, 7, 7, 7, 7, 7, 7, 7, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 9, 9, 9, 9, 1, 9, 9, 1, 9, 9])\n",
      "dict_values([2, 9, 9, 9, 9, 1, 9, 9, 9, 9, 1])\n",
      "dict_values([3, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([1, 6, 6, 6, 6, 1, 6, 6, 1, 6, 6])\n",
      "dict_values([2, 9, 9, 9, 9, 3, 9, 9, 3, 9, 9])\n",
      "dict_values([2, 9, 9, 9, 9, 3, 9, 9, 3, 9, 9])\n",
      "dict_values([2, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1])\n",
      "dict_values([1, 7, 7, 7, 7, 1, 7, 7, 1, 7, 7])\n",
      "dict_values([2, 8, 8, 8, 8, 1, 8, 8, 1, 8, 8])\n",
      "dict_values([3, 10, 10, 10, 10, 1, 10, 10, 1, 10, 10])\n",
      "dict_values([2, 9, 9, 9, 9, 3, 9, 9, 3, 9, 9])\n",
      "dict_values([2, 15, 15, 15, 15, 6, 15, 15, 7, 15, 15])\n",
      "dict_values([1, 8, 8, 8, 8, 1, 8, 8, 1, 8, 8])\n",
      "dict_values([1, 8, 8, 8, 8, 1, 8, 8, 1, 8, 8])\n",
      "dict_values([2, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1])\n",
      "dict_values([1, 10, 10, 10, 10, 3, 10, 10, 10, 10, 3])\n",
      "dict_values([2, 10, 10, 10, 10, 3, 10, 10, 3, 10, 10])\n",
      "dict_values([3, 9, 9, 9, 9, 9, 9, 3, 9, 9, 3])\n",
      "dict_values([3, 10, 10, 10, 10, 3, 10, 10, 3, 10, 10])\n",
      "dict_values([1, 8, 8, 8, 8, 1, 8, 8, 8, 8, 1])\n",
      "dict_values([2, 9, 9, 9, 9, 1, 9, 9, 1, 9, 9])\n",
      "dict_values([2, 10, 10, 10, 10, 3, 10, 10, 3, 10, 10])\n",
      "dict_values([3, 11, 11, 11, 11, 3, 11, 11, 3, 11, 11])\n",
      "dict_values([2, 9, 9, 9, 9, 9, 9, 3, 9, 9, 3])\n",
      "dict_values([3, 10, 10, 10, 10, 3, 10, 10, 3, 10, 10])\n",
      "dict_values([2, 9, 9, 9, 9, 3, 9, 9, 9, 9, 3])\n",
      "dict_values([3, 10, 10, 10, 10, 3, 10, 10, 3, 10, 10])\n",
      "dict_values([30, 96, 96, 96, 96, 96, 96, 96, 96, 7, 8])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 5, 5, 5, 5, 1, 5, 5, 1, 3, 5])\n",
      "dict_values([2, 17, 17, 17, 17, 17, 17, 17, 17, 13, 13])\n",
      "dict_values([2, 13, 13, 13, 13, 13, 13, 13, 13, 10, 10])\n",
      "dict_values([2, 13, 13, 13, 13, 13, 13, 13, 13, 11, 11])\n",
      "dict_values([2, 13, 13, 13, 13, 13, 13, 13, 13, 10, 10])\n",
      "dict_values([2, 13, 13, 13, 13, 13, 13, 13, 13, 11, 11])\n",
      "dict_values([2, 13, 13, 13, 13, 13, 13, 13, 13, 10, 10])\n",
      "dict_values([1, 19, 19, 19, 19, 2, 19, 19, 2, 19, 19])\n",
      "dict_values([2, 15, 15, 15, 15, 3, 15, 15, 3, 15, 15])\n",
      "dict_values([2, 15, 15, 15, 15, 3, 15, 15, 3, 15, 15])\n",
      "dict_values([3, 23, 23, 23, 23, 13, 23, 23, 13, 23, 23])\n",
      "dict_values([3, 23, 23, 23, 23, 13, 23, 23, 13, 23, 23])\n",
      "dict_values([2, 16, 16, 16, 16, 3, 16, 16, 3, 16, 16])\n",
      "dict_values([2, 16, 16, 16, 16, 3, 16, 16, 3, 16, 16])\n",
      "dict_values([3, 27, 27, 27, 27, 15, 27, 27, 15, 27, 27])\n",
      "dict_values([2, 26, 26, 26, 26, 13, 26, 26, 13, 26, 26])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([3, 18, 18, 18, 18, 12, 18, 18, 12, 18, 18])\n",
      "dict_values([1, 14, 14, 14, 14, 14, 14, 14, 14, 4, 4])\n",
      "dict_values([1, 21, 21, 21, 21, 21, 21, 21, 21, 3, 3])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1])\n",
      "dict_values([34, 7, 34, 34, 7, 3, 34, 34, 3, 7, 26])\n",
      "dict_values([29, 6, 29, 29, 6, 2, 29, 29, 2, 6, 25])\n",
      "dict_values([27, 5, 27, 27, 5, 1, 27, 27, 1, 5, 25])\n",
      "dict_values([18, 2, 18, 18, 2, 1, 18, 18, 1, 2, 14])\n",
      "dict_values([18, 2, 18, 18, 2, 18, 18, 1, 2, 14, 1])\n",
      "dict_values([24, 4, 24, 24, 4, 3, 24, 24, 3, 4, 20])\n",
      "dict_values([28, 6, 28, 28, 6, 1, 28, 28, 1, 6, 26])\n",
      "dict_values([31, 5, 31, 31, 5, 1, 31, 31, 1, 5, 23])\n",
      "dict_values([16, 2, 16, 16, 2, 1, 16, 16, 2, 12, 1])\n",
      "dict_values([33, 6, 33, 33, 6, 3, 33, 33, 3, 6, 26])\n",
      "dict_values([24, 4, 24, 24, 4, 2, 24, 24, 2, 4, 23])\n",
      "dict_values([25, 3, 25, 25, 3, 2, 25, 25, 2, 3, 21])\n",
      "dict_values([16, 2, 16, 16, 2, 1, 16, 16, 1, 2, 12])\n",
      "dict_values([33, 6, 33, 33, 6, 1, 33, 33, 1, 6, 25])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 10, 10, 3, 6, 10, 10, 6, 3, 3])\n",
      "dict_values([3, 4, 11, 11, 4, 8, 11, 11, 8, 4, 4])\n",
      "dict_values([3, 3, 10, 10, 3, 6, 10, 10, 6, 3, 3])\n",
      "dict_values([3, 4, 11, 11, 4, 8, 11, 11, 8, 4, 4])\n",
      "dict_values([3, 3, 10, 10, 3, 6, 10, 10, 6, 3, 3])\n",
      "dict_values([3, 3, 11, 11, 3, 6, 11, 11, 6, 3, 3])\n",
      "dict_values([3, 4, 11, 11, 4, 8, 11, 11, 8, 4, 4])\n",
      "dict_values([5, 1, 5, 5, 1, 1, 5, 5, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 10, 10, 10, 10, 10, 10, 10, 10, 3, 3])\n",
      "dict_values([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1])\n",
      "dict_values([1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([13, 13, 13, 13, 13, 2, 13, 13, 2, 13, 13])\n",
      "dict_values([13, 13, 13, 13, 13, 2, 13, 13, 2, 13, 13])\n",
      "dict_values([13, 13, 13, 13, 13, 1, 13, 13, 1, 13, 13])\n",
      "dict_values([13, 13, 13, 13, 13, 1, 13, 13, 1, 13, 13])\n",
      "dict_values([13, 13, 13, 13, 13, 2, 13, 13, 2, 13, 13])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1])\n",
      "dict_values([6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1])\n",
      "dict_values([6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1])\n",
      "dict_values([6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1])\n",
      "dict_values([1, 13, 13, 13, 13, 2, 13, 4, 2, 13, 13])\n",
      "dict_values([1, 13, 13, 13, 13, 2, 13, 4, 2, 13, 13])\n",
      "dict_values([2, 12, 12, 12, 12, 1, 12, 2, 1, 12, 12])\n",
      "dict_values([2, 11, 11, 11, 11, 1, 11, 2, 1, 11, 11])\n",
      "dict_values([1, 14, 14, 14, 14, 3, 14, 4, 3, 14, 14])\n",
      "dict_values([1, 10, 10, 10, 10, 1, 10, 2, 1, 10, 10])\n",
      "dict_values([2, 11, 11, 11, 11, 2, 11, 2, 2, 11, 11])\n",
      "dict_values([1, 14, 14, 14, 14, 2, 14, 4, 2, 14, 14])\n",
      "dict_values([1, 7, 7, 7, 7, 1, 7, 4, 1, 7, 7])\n",
      "dict_values([1, 7, 7, 7, 7, 2, 7, 4, 2, 7, 7])\n",
      "dict_values([1, 7, 7, 7, 7, 1, 7, 4, 1, 7, 7])\n",
      "dict_values([1, 6, 6, 6, 6, 1, 6, 4, 1, 6, 6])\n",
      "dict_values([6, 36, 35, 35, 36, 7, 35, 11, 7, 35, 35])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def select_wells(row):\n",
    "    wid = row['WID']\n",
    "    counter = Counter(row['PARLABEL'])\n",
    "    if len(counter) == len(chems):\n",
    "        print(counter.values())\n",
    "        if all(i >= 4 for i in counter.values()):\n",
    "            return  wid\n",
    "\n",
    "\n",
    "# Create mask of sample groups meeting parameter requirements.\n",
    "res = sample_groups.apply(select_wells, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mask to select sample results from wells that meet parameter requirements.\n",
    "spec_samples = spec_samples[spec_samples['WID'].isin(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188665\n",
      "3188665\n"
     ]
    }
   ],
   "source": [
    "print(len(samples))\n",
    "print(len(samples['SID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wells: 40\n"
     ]
    }
   ],
   "source": [
    "# number of unique wells\n",
    "nwells = len(spec_samples['WID'].unique())\n",
    "print('Number of wells: ' + str(nwells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample results to csv.\n",
    "#spec_samples.to_csv(results_path / '{}_spec_sample_results_11.csv'.format(area.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Groundwater Elevations to Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\work\\projects\\coast_slr\\scripts\\slr_ground_water_quality_\\elevation \n",
      "\n",
      "Loading GAMA groundwater elevations. \n",
      "\n",
      "[                  WELL NUMBER MEASUREMENT DATE  DEPTH TO WATER\n",
      "0               17S11E22E002S       1993-10-19          100.52\n",
      "1               17S11E22E002S       1994-03-14          100.41\n",
      "2               17S11E22E002S       1994-10-17          100.43\n",
      "3               17S11E22E002S       1995-03-29          100.36\n",
      "4               17S11E22E002S       1995-10-16          100.17\n",
      "...                       ...              ...             ...\n",
      "4229858  SL204131495 - REW-12       2021-11-16           72.20\n",
      "4229859  SL204131495 - REW-12       2021-12-07           72.33\n",
      "4229860  SL204131495 - REW-14       2017-04-04             NaN\n",
      "4229861  SL204131495 - REW-15       2017-04-04             NaN\n",
      "4229862   SL204131495 - REW-3       2017-04-04             NaN\n",
      "\n",
      "[4229863 rows x 3 columns]]\n",
      "Loading Geotracker groundwater elevations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Depth to Water Data\n",
    "# Load GAMA dtw data\n",
    "# Create elev_path.\n",
    "elev_path = bp / 'elevation'\n",
    "print(elev_path, '\\n')\n",
    "\n",
    "# Dictionary of data types for gama_elev gama_elev for open_table().\n",
    "gama_elev_dtypes = {\n",
    "    'WELL NUMBER' : 'string',\n",
    "    'DEPTH TO WATER' : 'float64',\n",
    "    }\n",
    "\n",
    "# Date column of gama_elev gama_elev for open_table().\n",
    "gama_elev_date = ['MEASUREMENT DATE']\n",
    "\n",
    "# Columns of gama_elev gama_elev for open_table().\n",
    "gama_elev_cols = list(gama_elev_dtypes.keys()) + gama_elev_date\n",
    "\n",
    "\n",
    "print('Loading GAMA groundwater elevations. \\n')\n",
    "\n",
    "# create list of files to open\n",
    "gama_elev_files = elev_path.glob('**/*gama*.zip')\n",
    "gama_elev_files = list(gama_elev_files)\n",
    "\n",
    "# Use list comprehension to create a list of dataframes from the files list. Uses open_table() to open the files.\n",
    "gama_elev_list = [open_table(i,dtypes = gama_elev_dtypes,date_cols = gama_elev_date, cols =gama_elev_cols) for i in gama_elev_files]\n",
    "print(gama_elev_list)\n",
    "\n",
    "# Concatenate the list of dataframes into one dataframe if there are more than one.\n",
    "if len(gama_elev_list) > 1:\n",
    "    gama_elev = pd.concat(gama_elev_list)\n",
    "\n",
    "else:\n",
    "    gama_elev = gama_elev_list[0]\n",
    "\n",
    "# Dict of attributes to rename.\n",
    "gama_geo_dict = {\n",
    "    'WELL NUMBER' : 'WID',\n",
    "    'DEPTH TO WATER' : 'DTW',\n",
    "    'MEASUREMENT DATE' : 'LOGDATE',\n",
    "}\n",
    "# Rename columns.\n",
    "gama_elev = gama_elev.rename(columns=gama_geo_dict)\n",
    "\n",
    "# Fix column formatting.\n",
    "gama_elev['LOGDATE'] = gama_elev['LOGDATE'].astype(str)\n",
    "gama_elev['WID'] = gama_elev['WID'].str.replace(' ', '')\n",
    "\n",
    "# Create GID (group id) column. GID is the WID and LOGDATE concatenated.\n",
    "gama_elev['GID'] = list(zip(gama_elev['WID'], gama_elev['LOGDATE']))\n",
    "# Load Geotracker DTW data.\n",
    "# Dictionary of data types for geo_elev geo_elev for open_table().\n",
    "geo_elev_dtypes = {\n",
    "    'GLOBAL_ID' : 'string',\n",
    "    'FIELD_POINT_NAME' : 'string',\n",
    "    'DTW' : 'float64',\n",
    "    }\n",
    "\n",
    "# Date column of geo_elev geo_elev for open_table().\n",
    "geo_elev_date = ['GW_MEAS_DATE']\n",
    "\n",
    "# Columns of geo_elev geo_elev for open_table().\n",
    "geo_elev_cols = list(geo_elev_dtypes.keys()) + geo_elev_date\n",
    "\n",
    "print('Loading Geotracker groundwater elevations. \\n')\n",
    "\n",
    "# create list of files to open\n",
    "geo_elev_files = elev_path.glob('**/*Geo*.zip')\n",
    "geo_elev_files = list(geo_elev_files)\n",
    "\n",
    "\n",
    "# Use list comprehension to create a list of dataframes from the files list. Uses open_table() to open the files.\n",
    "geo_elev_list = [open_table(i,geo_elev_dtypes,date_cols= geo_elev_date,cols =geo_elev_cols) for i in geo_elev_files]\n",
    "\n",
    "# Concatenate the list of dataframes into one dataframe if there are more than one.\n",
    "if len(geo_elev_list) > 1:\n",
    "    geo_elev = pd.concat(geo_elev_list)\n",
    "\n",
    "else:\n",
    "    geo_elev = geo_elev_list[0]\n",
    "\n",
    "# Create WID column.\n",
    "geo_elev['WID'] = geo_elev['GLOBAL_ID'] + '-' + geo_elev['FIELD_POINT_NAME']\n",
    "\n",
    "# Drop unnecessary columns.\n",
    "geo_elev = geo_elev.drop(columns=['GLOBAL_ID', 'FIELD_POINT_NAME'])\n",
    "\n",
    "# fix column formatting.\n",
    "geo_elev['WID'] = geo_elev['WID'].str.replace(' ', '')\n",
    "\n",
    "# Rename columns.\n",
    "geo_elev = geo_elev.rename(columns={'GW_MEAS_DATE' : 'LOGDATE'})\n",
    "\n",
    "# Fix column formatting.\n",
    "geo_elev['LOGDATE'] = geo_elev['LOGDATE'].astype(str)\n",
    "\n",
    "# Create GID (group id) column. GID is the WID and LOGDATE concatenated.\n",
    "geo_elev['GID'] = list(zip(geo_elev['WID'], geo_elev['LOGDATE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate gama_results and edf_results.\n",
    "dtw = pd.concat([geo_elev, gama_elev])\n",
    "dtw['dtw_units'] = 'ft'\n",
    "\n",
    "# List of columns that require a value.\n",
    "dtw_req_cols = ['WID','DTW','LOGDATE']\n",
    "\n",
    "# Drops rows with missing values in required columns.\n",
    "dtw = dtw.dropna(subset=dtw_req_cols)\n",
    "\n",
    "# Drop duplicate GID rows.\n",
    "dtw = dtw.drop_duplicates(subset=['GID'])\n",
    "samples_dtw = spec_samples.merge(dtw, left_on=['GID'], right_on=['GID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOGDATE</th>\n",
       "      <th>PARLABEL</th>\n",
       "      <th>PARVAL</th>\n",
       "      <th>PARVQ</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>WID</th>\n",
       "      <th>GID</th>\n",
       "      <th>SID</th>\n",
       "      <th>FIELD_PT_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>chem_name</th>\n",
       "      <th>comp_conc_val</th>\n",
       "      <th>exceedence</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29248</th>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>XYLENES</td>\n",
       "      <td>50.0</td>\n",
       "      <td>=</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009614226-OTAY-LCRS</td>\n",
       "      <td>(L10009614226-OTAY-LCRS, 2019-10-15)</td>\n",
       "      <td>((L10009614226-OTAY-LCRS, 2019-10-15), XYLENES)</td>\n",
       "      <td>LSP</td>\n",
       "      <td>32.598853</td>\n",
       "      <td>-117.008522</td>\n",
       "      <td>Xylenes (total)</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30682</th>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>XYLENES</td>\n",
       "      <td>37.0</td>\n",
       "      <td>=</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009614226-OTAY-LCRS</td>\n",
       "      <td>(L10009614226-OTAY-LCRS, 2015-10-28)</td>\n",
       "      <td>((L10009614226-OTAY-LCRS, 2015-10-28), XYLENES)</td>\n",
       "      <td>LSP</td>\n",
       "      <td>32.598853</td>\n",
       "      <td>-117.008522</td>\n",
       "      <td>Xylenes (total)</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.978857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31440</th>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>XYLENES</td>\n",
       "      <td>31.0</td>\n",
       "      <td>=</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009614226-OTAY-LCRS</td>\n",
       "      <td>(L10009614226-OTAY-LCRS, 2016-10-25)</td>\n",
       "      <td>((L10009614226-OTAY-LCRS, 2016-10-25), XYLENES)</td>\n",
       "      <td>LSP</td>\n",
       "      <td>32.598853</td>\n",
       "      <td>-117.008522</td>\n",
       "      <td>Xylenes (total)</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.982286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32138</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>XYLENES</td>\n",
       "      <td>27.0</td>\n",
       "      <td>=</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009614226-OTAY-LCRS</td>\n",
       "      <td>(L10009614226-OTAY-LCRS, 2020-10-06)</td>\n",
       "      <td>((L10009614226-OTAY-LCRS, 2020-10-06), XYLENES)</td>\n",
       "      <td>LSP</td>\n",
       "      <td>32.598853</td>\n",
       "      <td>-117.008522</td>\n",
       "      <td>Xylenes (total)</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.984571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32769</th>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>XYLENES</td>\n",
       "      <td>24.0</td>\n",
       "      <td>=</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009614226-OTAY-LCRS</td>\n",
       "      <td>(L10009614226-OTAY-LCRS, 2017-10-16)</td>\n",
       "      <td>((L10009614226-OTAY-LCRS, 2017-10-16), XYLENES)</td>\n",
       "      <td>LSP</td>\n",
       "      <td>32.598853</td>\n",
       "      <td>-117.008522</td>\n",
       "      <td>Xylenes (total)</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.986286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102604</th>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ND</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10002513368-RAM-LCRS</td>\n",
       "      <td>(L10002513368-RAM-LCRS, 2017-10-16)</td>\n",
       "      <td>((L10002513368-RAM-LCRS, 2017-10-16), CD)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cadmium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102623</th>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ND</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>SL209294204-QCEB</td>\n",
       "      <td>(SL209294204-QCEB, 2012-08-21)</td>\n",
       "      <td>((SL209294204-QCEB, 2012-08-21), CD)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cadmium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102626</th>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ND</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>SL209294204-QCEB</td>\n",
       "      <td>(SL209294204-QCEB, 2013-07-23)</td>\n",
       "      <td>((SL209294204-QCEB, 2013-07-23), CD)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cadmium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102656</th>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ND</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009474974-SYC-LCRS</td>\n",
       "      <td>(L10009474974-SYC-LCRS, 2016-10-26)</td>\n",
       "      <td>((L10009474974-SYC-LCRS, 2016-10-26), CD)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cadmium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102675</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ND</td>\n",
       "      <td>UG/L</td>\n",
       "      <td>L10009474974-SYC-LCRS</td>\n",
       "      <td>(L10009474974-SYC-LCRS, 2019-09-25)</td>\n",
       "      <td>((L10009474974-SYC-LCRS, 2019-09-25), CD)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cadmium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6035 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LOGDATE PARLABEL  PARVAL PARVQ UNITS                     WID  \\\n",
       "29248    2019-10-15  XYLENES    50.0     =  UG/L  L10009614226-OTAY-LCRS   \n",
       "30682    2015-10-28  XYLENES    37.0     =  UG/L  L10009614226-OTAY-LCRS   \n",
       "31440    2016-10-25  XYLENES    31.0     =  UG/L  L10009614226-OTAY-LCRS   \n",
       "32138    2020-10-06  XYLENES    27.0     =  UG/L  L10009614226-OTAY-LCRS   \n",
       "32769    2017-10-16  XYLENES    24.0     =  UG/L  L10009614226-OTAY-LCRS   \n",
       "...             ...      ...     ...   ...   ...                     ...   \n",
       "3102604  2017-10-16       CD     0.0    ND  UG/L   L10002513368-RAM-LCRS   \n",
       "3102623  2012-08-21       CD     0.0    ND  UG/L        SL209294204-QCEB   \n",
       "3102626  2013-07-23       CD     0.0    ND  UG/L        SL209294204-QCEB   \n",
       "3102656  2016-10-26       CD     0.0    ND  UG/L   L10009474974-SYC-LCRS   \n",
       "3102675  2019-09-25       CD     0.0    ND  UG/L   L10009474974-SYC-LCRS   \n",
       "\n",
       "                                          GID  \\\n",
       "29248    (L10009614226-OTAY-LCRS, 2019-10-15)   \n",
       "30682    (L10009614226-OTAY-LCRS, 2015-10-28)   \n",
       "31440    (L10009614226-OTAY-LCRS, 2016-10-25)   \n",
       "32138    (L10009614226-OTAY-LCRS, 2020-10-06)   \n",
       "32769    (L10009614226-OTAY-LCRS, 2017-10-16)   \n",
       "...                                       ...   \n",
       "3102604   (L10002513368-RAM-LCRS, 2017-10-16)   \n",
       "3102623        (SL209294204-QCEB, 2012-08-21)   \n",
       "3102626        (SL209294204-QCEB, 2013-07-23)   \n",
       "3102656   (L10009474974-SYC-LCRS, 2016-10-26)   \n",
       "3102675   (L10009474974-SYC-LCRS, 2019-09-25)   \n",
       "\n",
       "                                                     SID FIELD_PT_CLASS  \\\n",
       "29248    ((L10009614226-OTAY-LCRS, 2019-10-15), XYLENES)            LSP   \n",
       "30682    ((L10009614226-OTAY-LCRS, 2015-10-28), XYLENES)            LSP   \n",
       "31440    ((L10009614226-OTAY-LCRS, 2016-10-25), XYLENES)            LSP   \n",
       "32138    ((L10009614226-OTAY-LCRS, 2020-10-06), XYLENES)            LSP   \n",
       "32769    ((L10009614226-OTAY-LCRS, 2017-10-16), XYLENES)            LSP   \n",
       "...                                                  ...            ...   \n",
       "3102604        ((L10002513368-RAM-LCRS, 2017-10-16), CD)           <NA>   \n",
       "3102623             ((SL209294204-QCEB, 2012-08-21), CD)           <NA>   \n",
       "3102626             ((SL209294204-QCEB, 2013-07-23), CD)           <NA>   \n",
       "3102656        ((L10009474974-SYC-LCRS, 2016-10-26), CD)           <NA>   \n",
       "3102675        ((L10009474974-SYC-LCRS, 2019-09-25), CD)           <NA>   \n",
       "\n",
       "          LATITUDE   LONGITUDE        chem_name  comp_conc_val  exceedence  \\\n",
       "29248    32.598853 -117.008522  Xylenes (total)         1750.0       False   \n",
       "30682    32.598853 -117.008522  Xylenes (total)         1750.0       False   \n",
       "31440    32.598853 -117.008522  Xylenes (total)         1750.0       False   \n",
       "32138    32.598853 -117.008522  Xylenes (total)         1750.0       False   \n",
       "32769    32.598853 -117.008522  Xylenes (total)         1750.0       False   \n",
       "...            ...         ...              ...            ...         ...   \n",
       "3102604       <NA>        <NA>          Cadmium            5.0       False   \n",
       "3102623       <NA>        <NA>          Cadmium            5.0       False   \n",
       "3102626       <NA>        <NA>          Cadmium            5.0       False   \n",
       "3102656       <NA>        <NA>          Cadmium            5.0       False   \n",
       "3102675       <NA>        <NA>          Cadmium            5.0       False   \n",
       "\n",
       "         magnitude  \n",
       "29248    -0.971429  \n",
       "30682    -0.978857  \n",
       "31440    -0.982286  \n",
       "32138    -0.984571  \n",
       "32769    -0.986286  \n",
       "...            ...  \n",
       "3102604       -1.0  \n",
       "3102623       -1.0  \n",
       "3102626       -1.0  \n",
       "3102656       -1.0  \n",
       "3102675       -1.0  \n",
       "\n",
       "[6035 rows x 15 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LOGDATE_x', 'PARLABEL', 'PARVAL', 'UNITS', 'WID_x', 'LATITUDE',\n",
      "       'LONGITUDE', 'DTW', 'dtw_units'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "samples_dtw.columns\n",
    "\n",
    "dtw_req_cols = ['LOGDATE_x', 'UNITS','PARLABEL', 'PARVAL', 'WID_x', 'DTW', 'LATITUDE', 'LONGITUDE', 'dtw_units']\n",
    "\n",
    "for i in samples_dtw.columns:\n",
    "    if i not in dtw_req_cols:\n",
    "        samples_dtw = samples_dtw.drop(columns=i)\n",
    "\n",
    "print(samples_dtw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SanDiego 11 : \n",
      "\n",
      "There are 830 samples with depth to water values.\n",
      "Out of 6035 samples in the original dataframe.\n",
      "13.75% of samples. \n",
      "\n",
      "There are 7 wells with depth to water values.\n",
      "Out of 40 wells in the original dataframe.\n",
      "17.50% of  wells. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chem_num = str(len(chems))\n",
    "\n",
    "a = (len(spec_samples))\n",
    "b = (len(samples_dtw))\n",
    "c =((len(samples_dtw) / len(spec_samples)*100))\n",
    "c = \"{:.2f}\".format(c)\n",
    "\n",
    "print(area, chem_num,': \\n')\n",
    "print('There are ' + str(b) + ' samples with depth to water values.')\n",
    "print(\"Out of \" + str(a) + \" samples in the original dataframe.\")\n",
    "print(str(c) + \"% of samples. \\n\")\n",
    "\n",
    "a = (len(spec_samples['WID'].unique()))\n",
    "b = (len(samples_dtw['WID_x'].unique()))\n",
    "c = (b/a)*100\n",
    "c = \"{:.2f}\".format(c)\n",
    "\n",
    "print('There are ' + str(b) + ' wells with depth to water values.')\n",
    "print(\"Out of \" + str(a) + \" wells in the original dataframe.\")\n",
    "print(str(c) + \"% of  wells. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample results to csv.\n",
    "samples_dtw.to_csv(results_path / '{}_dd_dtw_sample_results_{}.csv'.format(area.lower(), chem_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot table for CCME Water Quality Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_results.rename(columns={'WID' : 'Station', 'LOGDATE' : 'Date'}, inplace=True)\n",
    "\n",
    "sample_results['PARLABEL'] = sample_results['PARLABEL'] + '_' + sample_results['units']\n",
    "\n",
    "pivot_table = pd.pivot_table(sample_results, index=['Station', 'Date'], columns=['PARLABEL'], values=['PARVAL'])\n",
    "ccme_wqi_data = pivot_table.reset_index()\n",
    "\n",
    "ccme_wqi_data.columns = ['Station', 'Date', 'AS_UG/L', 'BZME_UG/L', 'BZ_UG/L', 'CD_UG/L', 'DBCP_UG/L',\n",
    "       'EBZ_UG/L', 'EDB_UG/L', 'MTBE_UG/L', 'NO3N_MG/L', 'PB_UG/L', 'PCE_UG/L',\n",
    "       'TCE_UG/L', 'TCPR123_UG/L', 'THM_UG/L', 'XYLENES_UG/L']\n",
    "\n",
    "ccme_wqi_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccme_wqi_data.to_csv(results_path / '{}_ccme_wqi_conc_samples.csv'.format(county.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Sample Result Values at Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean of magnitudes for each WID in the exceedences dataframe.\n",
    "print('Calculating magnitudes for each WID \\n')\n",
    "print(samples_mcl.head())\n",
    "\n",
    "means = samples_mcl.groupby(['WID'])['magnitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join mean magnitudes to well locations.\n",
    "print('Merging geometric mean magnitudes to wells \\n')\n",
    "wells = wells.merge(means, how='inner', left_on='WID', right_index=True)\n",
    "wells = wells.set_index('WID').sort_index()\n",
    "\n",
    "# Save well mean magnitudes to csv.\n",
    "wells.to_csv(bp / 'wells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert well mean magnitudes to shapefile\n",
    "import geopandas as gpd\n",
    "\n",
    "# Create geodataframe from well mean magnitudes, uses long and lat columns as xy coordinates, NAD83 projection.\n",
    "gdf = gpd.GeoDataFrame(wells, geometry=gpd.points_from_xy(x=wells.LONGITUDE, y=wells.LATITUDE), crs='EPSG:4326')\n",
    "\n",
    "# Reproject to UTM 11N.\n",
    "gdf = gdf.to_crs('EPSG:26911')\n",
    "\n",
    "\n",
    "gdf.to_file(results_path / 'wells.shp'.format(county))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sample Groups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group samples by WID and LOGDATE apply list function to get list of PARLABELS for each group.\n",
    "sample_groups = samples_mcl.groupby(['WID', 'LOGDATE'])['PARLABEL'].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Contaminant List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to create a list of sample indexes where all contaminants in the contaminant list are present.\n",
    "index_list = [i for i in sample_groups.index if all(item in sample_groups.loc[i] for item in contaminants_3)]\n",
    "\n",
    "# Uses index_list to create a dataframe of samples that meet the criteria.\n",
    "sample_group_results = samples_mcl[samples_mcl['GID'].isin(index_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print groups of samples that meet the criteria.\n",
    "print('Groups: ',len(index_list))\n",
    "print('Samples: ',len(sample_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join location data to sample results.\n",
    "sample_group_results = sample_results.merge(wells, left_on='WID', right_on='WID', how='inner')\n",
    "\n",
    "# Save sample group results to csv.\n",
    "sample_group_results.to_csv(bp / '{}_sample_results.csv'.format(county.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_results.to_csv(bp / '{}_sample_results.csv'.format(county.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contaminant Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Create list of all combinations of all contaminants\n",
    "combinations_list = list(combinations(contaminants_3, 10))\n",
    "len(combinations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select sample groups based on combinations of contaminants.\n",
    "def get_select_samples(row, contaminants):\n",
    "\n",
    "    # checks list of contaminants in row against list of contaminants in function call.\n",
    "    # if all contaminants in row are in contaminants, return True.\n",
    "    if all(item in row for item in contaminants):\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_samples(row, contaminants):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for values in row:\n",
    "        print(values)\n",
    "        if all(item in values for item in contaminants):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_dict = {}\n",
    "\n",
    "total =  len(combinations_list)\n",
    "count = 0\n",
    "\n",
    "for contaminants in combinations_list:\n",
    "\n",
    "    count += 1\n",
    "    percent = int(((count/total)*100))\n",
    "\n",
    "    ser = sample_groups.apply(get_select_samples, contaminants=contaminants_3)\n",
    "\n",
    "    ser_dict[contaminants] = ser\n",
    "\n",
    "    #print('{}%'.format(percent))\n",
    "    \n",
    "combo_stats = pd.DataFrame.from_dict(ser_dict, orient='index')\n",
    "\n",
    "print(combo_stats.max())\n",
    "print(list(combo_stats.idxmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modin Combo Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_samples_modin(row, contaminants):\n",
    "    print(row)\n",
    "\n",
    "    if all(element in row for element in contaminants) ==  True:\n",
    "        print('contains all elements')\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        print('does not contain all elements')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_modin = mpd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as mpd\n",
    "from distributed import Client\n",
    "client = Client()\n",
    "\n",
    "sample_groups_modin = mpd.DataFrame(sample_groups)\n",
    "\n",
    "\n",
    "ser_dict = {}\n",
    "\n",
    "for contaminants in combinations_list:\n",
    "\n",
    "    ser = sample_groups_modin.apply(get_select_samples_modin, contaminants=contaminants)\n",
    "    ser = ser[ser == True]\n",
    "\n",
    "    ser_dict[contaminants] = len(ser)\n",
    "\n",
    "\n",
    "\n",
    "print(max(ser_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_stats.max())\n",
    "print(list(combo_stats.idxmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading MCL table \\n')\n",
    "\n",
    "# Create path to mcl table.\n",
    "mcl_path = bp / 'MCL_list_1.xlsx'\n",
    "\n",
    "# Open mcl table.\n",
    "mcl = pd.read_excel(mcl_path, engine='openpyxl')\n",
    "\n",
    "# join MCL values to sample results\n",
    "print('Joining MCL values to samples \\n')\n",
    "samples_mcl = select_samples.merge(mcl, left_on='PARLABEL', right_on='chem_abrv', how='left').set_index(select_samples.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples_mcl to csv.\n",
    "alt = input(\"Input filename ending for 'county'_select_samples_'input'.csv: \")\n",
    "name = '{}_select_samples_{}.csv'.format(county.lower(), alt)\n",
    "sp = bp / name\n",
    "samples_mcl.to_csv(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of samples for each contaminant.\n",
    "parlabel_stats = samples['PARLABEL'].value_counts()\n",
    "\n",
    "# Create a dataframe with the counts of samples for each contaminant.\n",
    "parlabel_stats = parlabel_stats.to_frame(name='COUNTS').reset_index().rename(columns={'index':'PARLABEL'})\n",
    "\n",
    "# Create PERCENT column for each contaminant. Showing percent of samples for each contaminant compared to total samples.\n",
    "parlabel_stats['PERCENT'] = (parlabel_stats['COUNTS'] / len(samples) * 100).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples_mcl to csv.\n",
    "name = '{}_parlabel_stats.csv'.format(county.lower())\n",
    "sp = bp / name\n",
    "parlabel_stats.to_csv(sp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23234625f55973f7a58126a35d86facfdbb1213f4cf262be4a4984331c60271a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('geoprj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
